from utils.algorithm_runner import update_game_state, check_goal, handle_frame, algorithm_finished
import pygame
import time
import math

def manhattan_distance(pos1, pos2):
    """T√≠nh kho·∫£ng c√°ch Manhattan"""
    return abs(pos1[0] - pos2[0]) + abs(pos1[1] - pos2[1])

def run_minimax(game):
    """
    Thu·∫≠t to√°n Minimax c·∫£i ti·∫øn:
    - Player: T√¨m ƒë∆∞·ªùng ƒë·∫øn goal nh∆∞ng TR√ÅNH Monster 
    - Monster: Di chuy·ªÉn 2 √¥ m·ªói l∆∞·ª£t ƒë·ªÉ ƒëu·ªïi theo Player
    - S·ª≠ d·ª•ng Minimax thu·∫ßn t√∫y v·ªõi defensive strategy
    """
    game.alg_name = "Minimax Defense (Player vs Fast Monster)"

    start_pos = getattr(game, 'custom_start', (0, 0))
    if start_pos is None:
        start_pos = (0, 0)
    
    goal_pos = getattr(game, 'custom_end', None)
    if goal_pos is None:
        goal_pos = (len(game.maze)-1, len(game.maze[0])-1)

    # V·ªã tr√≠ ban ƒë·∫ßu
    player_pos = start_pos  # Max player (xanh)
    
    # T√¨m v·ªã tr√≠ h·ª£p l·ªá cho monster (xa player nh·∫•t c√≥ th·ªÉ, nh∆∞ng kh√¥ng tr√πng goal)
    monster_pos = None
    max_distance = 0
    for i in range(len(game.maze)):
        for j in range(len(game.maze[0])):
            if (game.maze[i][j] == 0 and  # V·ªã tr√≠ h·ª£p l·ªá
                (i, j) != goal_pos and    # Kh√¥ng tr√πng goal
                (i, j) != player_pos):    # Kh√¥ng tr√πng player
                distance = manhattan_distance((i, j), player_pos)
                if distance > max_distance:
                    max_distance = distance
                    monster_pos = (i, j)
    
    if monster_pos is None:
        # Fallback: t√¨m v·ªã tr√≠ g·∫ßn goal nh∆∞ng kh√¥ng tr√πng
        for dx, dy in [(0, 1), (1, 0), (0, -1), (-1, 0), (1, 1), (-1, -1), (1, -1), (-1, 1)]:
            new_x, new_y = goal_pos[0] + dx, goal_pos[1] + dy
            if (0 <= new_x < len(game.maze) and 0 <= new_y < len(game.maze[0]) and 
                game.maze[new_x][new_y] == 0):
                monster_pos = (new_x, new_y)
                break
        
        if monster_pos is None:
            monster_pos = player_pos  # Last resort
    
    print(f"B·∫Øt ƒë·∫ßu: Player t·∫°i {player_pos}, Monster t·∫°i {monster_pos}, Goal t·∫°i {goal_pos}")
    
    visited = set()
    game.backtracked_nodes = set()
    step_count = 0
    max_depth = 3  # Gi·∫£m ƒë·ªô s√¢u ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô
    
    # Tracking ƒë·ªÉ tr√°nh v√≤ng l·∫∑p
    player_history = []  # L∆∞u l·ªãch s·ª≠ di chuy·ªÉn c·ªßa player
    monster_history = []  # L∆∞u l·ªãch s·ª≠ di chuy·ªÉn c·ªßa monster
    position_frequency = {}  # ƒê·∫øm s·ªë l·∫ßn ƒë·∫øn m·ªói v·ªã tr√≠
    
    # Th√™m thu·ªôc t√≠nh ƒë·ªÉ tracking positions
    game.player_pos = player_pos
    game.monster_pos = monster_pos
    
    def get_possible_moves(pos, is_player=True, recent_positions=None, target_pos=None):
        """L·∫•y c√°c n∆∞·ªõc ƒëi h·ª£p l·ªá t·ª´ v·ªã tr√≠, tr√°nh v√≤ng l·∫∑p"""
        moves = []
        x, y = pos
        
        if is_player:
            # Player di chuy·ªÉn 1 √¥ m·ªói l∆∞·ª£t
            directions = [(0, 1), (1, 0), (0, -1), (-1, 0)]
            for dx, dy in directions:
                new_x, new_y = x + dx, y + dy
                if (0 <= new_x < len(game.maze) and 0 <= new_y < len(game.maze[0]) and 
                    game.maze[new_x][new_y] == 0):
                    moves.append((new_x, new_y))
        else:
            # Monster di chuy·ªÉn t·ªëi ƒëa 2 √¥ m·ªói l∆∞·ª£t v·ªÅ ph√≠a Player - HI·ªÜU QU·∫¢ H·ªíN
            if not target_pos:
                moves.append(pos)  # ƒê·ª©ng y√™n n·∫øu kh√¥ng c√≥ target
                return moves
            
            # T√≠nh kho·∫£ng c√°ch hi·ªán t·∫°i ƒë·∫øn Player
            current_dist = manhattan_distance(pos, target_pos)
            
            # Th·ª≠ t·∫•t c·∫£ c√°c combo di chuy·ªÉn c√≥ th·ªÉ v√† ƒë√°nh gi√° hi·ªáu qu·∫£
            move_candidates = []
            
            # Th·ª≠ di chuy·ªÉn 1 √¥ theo t·∫•t c·∫£ h∆∞·ªõng
            all_dirs = [(0, 1), (1, 0), (0, -1), (-1, 0)]
            for dx, dy in all_dirs:
                mid_x, mid_y = x + dx, y + dy
                if (0 <= mid_x < len(game.maze) and 0 <= mid_y < len(game.maze[0]) and 
                    game.maze[mid_x][mid_y] == 0):
                    
                    # ƒê√°nh gi√° move 1 √¥
                    dist_1_step = manhattan_distance((mid_x, mid_y), target_pos)
                    improvement_1 = current_dist - dist_1_step
                    move_candidates.append((improvement_1, (mid_x, mid_y)))
                    
                    # Th·ª≠ ti·∫øp di chuy·ªÉn √¥ th·ª© 2 theo c√πng h∆∞·ªõng
                    final_x, final_y = mid_x + dx, mid_y + dy
                    if (0 <= final_x < len(game.maze) and 0 <= final_y < len(game.maze[0]) and 
                        game.maze[final_x][final_y] == 0):
                        dist_2_step = manhattan_distance((final_x, final_y), target_pos)
                        improvement_2 = current_dist - dist_2_step
                        move_candidates.append((improvement_2, (final_x, final_y)))
                    
                    # Th·ª≠ di chuy·ªÉn √¥ th·ª© 2 theo h∆∞·ªõng kh√°c (di chuy·ªÉn ch√©o)
                    for dx2, dy2 in all_dirs:
                        if (dx2, dy2) != (dx, dy):  # H∆∞·ªõng kh√°c
                            final_x, final_y = mid_x + dx2, mid_y + dy2
                            if (0 <= final_x < len(game.maze) and 0 <= final_y < len(game.maze[0]) and 
                                game.maze[final_x][final_y] == 0):
                                dist_corner = manhattan_distance((final_x, final_y), target_pos)
                                improvement_corner = current_dist - dist_corner
                                move_candidates.append((improvement_corner, (final_x, final_y)))
            
            # S·∫Øp x·∫øp theo m·ª©c ƒë·ªô c·∫£i thi·ªán (t·ªët nh·∫•t tr∆∞·ªõc)
            move_candidates.sort(reverse=True, key=lambda x: x[0])
            
            # L·∫•y c√°c moves t·ªët nh·∫•t (ch·ªâ nh·ªØng moves c·∫£i thi·ªán kho·∫£ng c√°ch)
            for improvement, move in move_candidates:
                if improvement > 0:  # Ch·ªâ l·∫•y moves l√†m g·∫ßn Player h∆°n
                    moves.append(move)
            
            # N·∫øu kh√¥ng c√≥ move n√†o c·∫£i thi·ªán, l·∫•y move √≠t x·∫•u nh·∫•t
            if not moves and move_candidates:
                moves.append(move_candidates[0][1])
            
            # Lo·∫°i b·ªè tr√πng l·∫∑p v√† gi·ªõi h·∫°n s·ªë l∆∞·ª£ng
            moves = list(dict.fromkeys(moves))  # Gi·ªØ th·ª© t·ª± v√† lo·∫°i tr√πng
            if len(moves) > 6:  # Gi·ªõi h·∫°n ƒë·ªÉ tr√°nh qu√° nhi·ªÅu options
                moves = moves[:6]
        
        # Tr√°nh v√≤ng l·∫∑p: ∆∞u ti√™n moves ch∆∞a ƒëi g·∫ßn ƒë√¢y
        if recent_positions and len(moves) > 1:
            # S·∫Øp x·∫øp moves theo m·ª©c ƒë·ªô "m·ªõi"
            def move_priority(move):
                if move in recent_positions[-3:]:  # ƒê√£ ƒëi trong 3 b∆∞·ªõc g·∫ßn ƒë√¢y
                    return 1  # ∆Øu ti√™n th·∫•p
                elif move in recent_positions:
                    return 2  # ∆Øu ti√™n trung b√¨nh
                else:
                    return 0  # ∆Øu ti√™n cao (ch∆∞a ƒëi)
            
            moves.sort(key=move_priority)
        
        # N·∫øu kh√¥ng c√≥ n∆∞·ªõc ƒëi n√†o, cho ph√©p ƒë·ª©ng y√™n
        if not moves:
            moves.append(pos)
            
        return moves
    
    def evaluate_state(player_pos, monster_pos, player_prev=None, monster_prev=None):
        """
        H√†m ƒë√°nh gi√° tr·∫°ng th√°i:
        - Player t√¨m ƒë∆∞·ªùng ƒë·∫øn goal nh∆∞ng TR√ÅNH Monster
        - Monster ƒëu·ªïi theo Player v·ªõi t·ªëc ƒë·ªô 2 √¥/l∆∞·ª£t
        """
        # Kho·∫£ng c√°ch t·ª´ player ƒë·∫øn goal
        dist_to_goal = manhattan_distance(player_pos, goal_pos)
        
        # Kho·∫£ng c√°ch gi·ªØa player v√† monster
        dist_player_monster = manhattan_distance(player_pos, monster_pos)
        
        # Player th·∫Øng n·∫øu ƒë·∫øn goal
        if player_pos == goal_pos:
            return 1000
        
        # Monster th·∫Øng n·∫øu b·∫Øt ƒë∆∞·ª£c player
        if player_pos == monster_pos:
            return -1000
        
        # Heuristic c√¢n b·∫±ng: Player tr√°nh Monster, Monster t√≠ch c·ª±c b·∫Øt Player
        score = 0
        
        # 1. Player ∆∞u ti√™n ti·∫øn v·ªÅ goal (nh∆∞ng kh√¥ng qu√° cao)
        score -= dist_to_goal * 20
        
        # 2. Monster ∆∞u ti√™n B·∫ÆT Player (M·ª®C ƒê·ªò CAO NH·∫§T!)
        if dist_player_monster <= 2:  # Monster r·∫•t g·∫ßn = c·ª±c k·ª≥ nguy hi·ªÉm cho Player
            score -= dist_player_monster * 100  # TƒÉng M·∫†NH ƒë·ªÉ Monster ∆∞u ti√™n b·∫Øt
        elif dist_player_monster <= 4:  # Monster g·∫ßn = nguy hi·ªÉm
            score -= dist_player_monster * 60
        else:  # Monster xa = Monster c·∫ßn ti·∫øn g·∫ßn
            score -= dist_player_monster * 30
        
        # 3. Player M·∫†NH M·∫º tr√°nh Monster khi g·∫ßn
        if dist_player_monster <= 3:  # Monster g·∫ßn = Player c·∫ßn tr√°nh g·∫•p
            score += dist_player_monster * 80  # Bonus M·∫†NH cho vi·ªác xa Monster
        elif dist_player_monster <= 5:  # Monster h∆°i g·∫ßn = c·∫©n th·∫≠n
            score += dist_player_monster * 40
        
        # 4. Khi Player an to√†n (Monster xa), t·∫≠p trung v·ªÅ goal
        if dist_player_monster > 5:
            score -= dist_to_goal * 15  # TƒÉng ∆∞u ti√™n goal khi an to√†n
        
        # Bonus m·∫°nh cho vi·ªác di chuy·ªÉn ƒë√∫ng h∆∞·ªõng
        if player_prev and player_pos != player_prev:
            # Ki·ªÉm tra n·∫øu Player ti·∫øn g·∫ßn goal h∆°n
            prev_dist_to_goal = manhattan_distance(player_prev, goal_pos)
            if dist_to_goal < prev_dist_to_goal:
                score += 15  # Bonus l·ªõn cho vi·ªác ti·∫øn v·ªÅ goal
            else:
                score -= 5   # Penalty cho vi·ªác xa goal h∆°n
        
        if monster_prev and monster_pos != monster_prev:
            # Ki·ªÉm tra n·∫øu Monster ti·∫øn g·∫ßn player h∆°n
            prev_dist_to_player = manhattan_distance(monster_prev, player_pos)
            if dist_player_monster < prev_dist_to_player:
                score -= 15  # Bonus l·ªõn cho Monster (x·∫•u cho Player)
            else:
                score += 5   # Penalty cho Monster (t·ªët cho Player)
        
        # Penalty m·∫°nh cho vi·ªác ƒë·ª©ng y√™n
        if player_prev and player_pos == player_prev:
            score -= 20  # Player ƒë·ª©ng y√™n = r·∫•t x·∫•u
        if monster_prev and monster_pos == monster_prev:
            score += 10  # Monster ƒë·ª©ng y√™n = kh√° t·ªët cho player
        
        return score
    
    def minimax_pure(player_pos, monster_pos, depth, player_hist=None, monster_hist=None):
        """
        Minimax thu·∫ßn t√∫y - kh√¥ng c√≥ Alpha-Beta pruning
        Duy·ªát t·∫•t c·∫£ c√°c n∆∞·ªõc ƒëi c√≥ th·ªÉ ƒë·ªÉ t√¨m n∆∞·ªõc ƒëi t·ªët nh·∫•t
        Tr·∫£ v·ªÅ (eval_score, best_player_move, best_monster_move)
        """
        # Base cases
        if depth == 0:
            p_prev = player_hist[-1] if player_hist else None
            m_prev = monster_hist[-1] if monster_hist else None
            return evaluate_state(player_pos, monster_pos, p_prev, m_prev), None, None
        
        if player_pos == goal_pos:
            return 1000, None, None
        
        if player_pos == monster_pos:
            return -1000, None, None
        
        # Player t·ªëi ƒëa h√≥a, Monster t·ªëi thi·ªÉu h√≥a
        best_eval = -math.inf
        best_player_move = None
        best_monster_move = None
        
        player_moves = get_possible_moves(player_pos, is_player=True, recent_positions=player_hist)
        monster_moves = get_possible_moves(monster_pos, is_player=False, recent_positions=monster_hist, target_pos=player_pos)
        
        # Th·ª≠ t·∫•t c·∫£ k·∫øt h·ª£p player-monster moves
        for p_move in player_moves:
            for m_move in monster_moves:
                # Ki·ªÉm tra n·∫øu move collision (c·∫£ hai ƒë·∫øn c√πng v·ªã tr√≠)
                if p_move == m_move:
                    continue  # Skip moves va ch·∫°m
                
                new_player_hist = (player_hist + [player_pos]) if player_hist else [player_pos]
                new_monster_hist = (monster_hist + [monster_pos]) if monster_hist else [monster_pos]
                
                eval_score, _, _ = minimax_pure(p_move, m_move, depth-1, 
                                              new_player_hist, new_monster_hist)
                
                # Player perspective: C√¢n b·∫±ng gi·ªØa goal v√† tr√°nh Monster
                goal_dist_current = manhattan_distance(player_pos, goal_pos)
                goal_dist_new = manhattan_distance(p_move, goal_pos)
                monster_dist_current = manhattan_distance(player_pos, monster_pos)
                monster_dist_new = manhattan_distance(p_move, m_move)
                
                # Bonus cho Player ti·∫øn v·ªÅ goal (nh∆∞ng kh√¥ng qu√° m·∫°nh)
                if goal_dist_new < goal_dist_current:
                    eval_score += 15
                elif goal_dist_new > goal_dist_current:
                    eval_score -= 10
                
                # Bonus M·∫†NH cho Player tr√°nh Monster
                if monster_dist_current <= 3:  # Monster g·∫ßn = ∆∞u ti√™n tr√°nh
                    if monster_dist_new > monster_dist_current:
                        eval_score += 25  # Bonus l·ªõn cho vi·ªác tr√°nh Monster
                    else:
                        eval_score -= 20  # Penalty cho vi·ªác ƒë·∫øn g·∫ßn Monster
                elif monster_dist_current <= 5:  # Monster h∆°i g·∫ßn = c·∫©n th·∫≠n
                    if monster_dist_new > monster_dist_current:
                        eval_score += 10
                    else:
                        eval_score -= 8
                
                # Penalty cho Player quay l·∫°i v·ªã tr√≠ c≈©
                if player_hist and p_move in player_hist[-3:]:
                    penalty = len([pos for pos in player_hist[-3:] if pos == p_move]) * 5
                    eval_score -= penalty  # TƒÉng penalty
                
                # Monster perspective: SI√äU T√çCH C·ª∞C ƒëu·ªïi theo Player
                player_dist_current = manhattan_distance(monster_pos, player_pos)
                player_dist_new = manhattan_distance(m_move, p_move)  # Kho·∫£ng c√°ch sau khi c·∫£ hai di chuy·ªÉn
                
                # Bonus M·∫†NH M·∫º cho Monster ti·∫øn g·∫ßn Player
                distance_improvement = player_dist_current - player_dist_new
                if distance_improvement > 0:  # Monster ti·∫øn g·∫ßn Player
                    # Bonus tƒÉng theo c·∫•p s·ªë khi Monster g·∫ßn Player
                    if player_dist_new <= 2:  # R·∫•t g·∫ßn = bonus c·ª±c l·ªõn
                        eval_score -= distance_improvement * 50
                    elif player_dist_new <= 4:  # G·∫ßn = bonus l·ªõn
                        eval_score -= distance_improvement * 30
                    else:  # Xa = bonus th∆∞·ªùng
                        eval_score -= distance_improvement * 20
                elif distance_improvement < 0:  # Monster xa Player h∆°n
                    penalty = abs(distance_improvement) * 15
                    eval_score += penalty  # Penalty cho Monster
                
                # Bonus ƒë·∫∑c bi·ªát n·∫øu Monster c√≥ th·ªÉ b·∫Øt Player trong 1-2 move
                if player_dist_new <= 1:  # Monster s·∫Øp b·∫Øt ƒë∆∞·ª£c Player
                    eval_score -= 100  # Bonus c·ª±c l·ªõn cho t√¨nh hu·ªëng n√†y
                
                # Monster penalty cho vi·ªác quay l·∫°i
                if monster_hist and m_move in monster_hist[-2:]:
                    eval_score += 3  # TƒÉng penalty cho Monster l·∫∑p l·∫°i
                
                if eval_score > best_eval:
                    best_eval = eval_score
                    best_player_move = p_move
                    best_monster_move = m_move
        
        return best_eval, best_player_move, best_monster_move
    
    # Game loop
    game_over = False
    moves_count = 0
    max_moves = 200  # Gi·ªõi h·∫°n s·ªë n∆∞·ªõc ƒëi
    player_history = []  # Theo d√µi l·ªãch s·ª≠ Player
    monster_history = []  # Theo d√µi l·ªãch s·ª≠ Monster
    
    while game.is_running and not game_over and moves_count < max_moves:
        # Handle frame
        step_count, ok = handle_frame(game, step_count)
        if not ok:
            return
        
        # C·∫≠p nh·∫≠t tr·∫°ng th√°i hi·ªÉn th·ªã
        visited.add(player_pos)
        update_game_state(game, player_pos[0], player_pos[1], visited)
        
        # C·∫≠p nh·∫≠t v·ªã tr√≠ hi·ªán t·∫°i ƒë·ªÉ hi·ªÉn th·ªã
        game.current_node = player_pos
        game.path = [player_pos]
        game.player_pos = player_pos
        game.monster_pos = monster_pos
        
        # V·∫Ω frame
        game.draw_frame()
        time.sleep(0.5)
        
        # Ki·ªÉm tra ƒëi·ªÅu ki·ªán th·∫Øng/thua
        if player_pos == goal_pos:
            print("üéâ PLAYER TH·∫ÆNG! üéâ")
            print("Player ƒë√£ ƒë·∫øn ƒë∆∞·ª£c ƒë√≠ch th√†nh c√¥ng!")
            game_over = True
            break
        
        if player_pos == monster_pos:
            print("üíÄ GAME OVER! üíÄ")
            print("Monster ƒë√£ b·∫Øt ƒë∆∞·ª£c Player!")
            print(f"Player b·ªã b·∫Øt t·∫°i v·ªã tr√≠: {player_pos}")
            game_over = True
            break
        
        # Ch·∫°y Minimax thu·∫ßn t√∫y ƒë·ªÉ t√¨m n∆∞·ªõc ƒëi t·ªët nh·∫•t
        _, best_player_move, best_monster_move = minimax_pure(
            player_pos, monster_pos, max_depth, 
            player_history[-5:], monster_history[-5:]  # Ch·ªâ x√©t 5 b∆∞·ªõc g·∫ßn nh·∫•t
        )
        
        # Debug th√¥ng tin
        if moves_count < 5:  # Ch·ªâ debug 5 move ƒë·∫ßu
            print(f"  Minimax suggest: Player {player_pos} -> {best_player_move}, Monster {monster_pos} -> {best_monster_move}")
        
        # Th·ª±c hi·ªán n∆∞·ªõc ƒëi v√† c·∫≠p nh·∫≠t l·ªãch s·ª≠
        if best_player_move and best_player_move != player_pos:
            player_history.append(player_pos)  # L∆∞u v·ªã tr√≠ c≈©
            player_pos = best_player_move
        
        # Monster ƒëi sau (c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh ƒë·ªÉ ƒëi c√πng l√∫c)
        if best_monster_move and best_monster_move != monster_pos:
            monster_history.append(monster_pos)  # L∆∞u v·ªã tr√≠ c≈©
            monster_pos = best_monster_move
        
        moves_count += 1
        step_count += 1
        
        # Hi·ªÉn th·ªã th√¥ng tin
        print(f"Move {moves_count}: Player at {player_pos}, Monster at {monster_pos}")
    
    if moves_count >= max_moves:
        print(" Game k·∫øt th√∫c do qu√° nhi·ªÅu n∆∞·ªõc ƒëi!")
    
    # K·∫øt th√∫c
    game.is_running = False
    game.current_node = None
    
    # Ki·ªÉm tra goal cu·ªëi c√πng
    if player_pos == goal_pos:
        if check_goal(game, player_pos[0], player_pos[1], [player_pos]):
            return
    
    algorithm_finished(game)

def is_valid_move(game, x, y):
    """Ki·ªÉm tra n∆∞·ªõc ƒëi h·ª£p l·ªá"""
    return (0 <= x < len(game.maze) and 0 <= y < len(game.maze[0]) and 
            game.maze[x][y] == 0)
